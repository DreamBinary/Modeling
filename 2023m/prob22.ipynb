{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[ 0.8574, -0.4140, -0.3198, -0.4457,  0.8582],\n         [ 0.8071, -0.4477, -1.1585, -0.3674, -1.0011],\n         [ 0.8071, -0.4477, -1.1585, -0.3674, -1.0011],\n         [-0.2083,  2.6161,  1.1718, -0.6004, -0.7228],\n         [ 0.8459, -0.3197, -1.0808, -0.9137, -0.4593]]],\n       grad_fn=<EmbeddingBackward0>)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# an Embedding module containing 10 tensors of size 3\n",
    "embedding = nn.Embedding(26, 5)\n",
    "# a batch of 2 samples of 4 indices each\n",
    "# \"happy\"\n",
    "input = torch.LongTensor([[12,0,0,19, 25]])\n",
    "\n",
    "output = embedding(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (l1): Sequential(\n",
      "    (0): Linear(in_features=5, out_features=30, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (l2): Sequential(\n",
      "    (0): Linear(in_features=30, out_features=5, bias=True)\n",
      "  )\n",
      "  (l3): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_multilabel_classification\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X = input\n",
    "# y = torch.Tensor([0.1, 0.2, 0.3, 0.3, 0.1])\n",
    "\n",
    "def get_dataset():\n",
    "    X, y = make_multilabel_classification(\n",
    "        n_samples=1000,\n",
    "        n_features=5,\n",
    "        n_classes=5,\n",
    "        n_labels=5,\n",
    "        random_state=1)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "X, y = get_dataset()\n",
    "n_inputs, n_outputs = X.shape[1], y.shape[1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_train = torch.from_numpy(y_train).float()\n",
    "y_test = torch.from_numpy(y_test).float()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, num_hiddens):\n",
    "        super(MLP, self).__init__()\n",
    "        self.l1 = nn.Sequential(\n",
    "            nn.Linear(n_inputs, num_hiddens),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.l2 = nn.Sequential(\n",
    "            nn.Linear(num_hiddens, n_outputs),\n",
    "        )\n",
    "        self.l3 = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.l2(x)\n",
    "        print(x)\n",
    "        x = self.l3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "num_hiddens = 30\n",
    "model = MLP(n_inputs, n_outputs, num_hiddens)\n",
    "print(model)\n",
    "\n",
    "loss = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "def evaluate_accuracy(X, y, model):\n",
    "    pred = model(X)\n",
    "    correct = sum(row.all().int().item() for row in (pred.ge(0.5) == y))\n",
    "    n = y.shape[0]\n",
    "    return correct / n\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1326,  2.4250,  0.3563, -0.6174,  2.9625],\n",
      "        [-0.5827,  2.1735,  0.3389, -0.6763,  4.2044],\n",
      "        [-0.4187,  2.8337,  0.2615, -0.8093,  3.8168],\n",
      "        [-1.1313,  3.3658,  0.9712, -1.2539,  3.7634],\n",
      "        [-0.4948,  2.2573,  0.2954, -0.6889,  4.5231],\n",
      "        [-0.3878,  1.3547,  0.0703, -0.0409,  3.2050],\n",
      "        [-0.1161,  0.9345, -0.1246,  0.9558,  3.8905],\n",
      "        [-0.5236,  2.2683,  0.6468, -0.8159,  3.1993],\n",
      "        [-0.1719,  0.9115,  0.1426,  1.1764,  2.5397],\n",
      "        [-1.0050,  2.8979,  0.7040,  0.2696,  4.7130],\n",
      "        [-0.2625,  1.2295,  0.2312,  0.2468,  2.7478],\n",
      "        [-0.5449,  1.6003, -0.1598, -0.1949,  4.0504],\n",
      "        [-0.3890,  2.0383,  0.2318, -0.3052,  3.0142],\n",
      "        [-0.6020,  1.8327, -0.0936, -0.8414,  4.0182],\n",
      "        [-0.5390,  1.8215,  0.0065, -0.4215,  4.1499],\n",
      "        [-0.8213,  2.5234,  0.2010, -0.8628,  4.4653],\n",
      "        [-0.5379,  2.0609,  0.4513,  0.8587,  3.8176],\n",
      "        [-0.3763,  2.5103,  0.6020, -1.4237,  4.3203],\n",
      "        [-0.6916,  2.0400,  0.3207,  0.3943,  4.2913],\n",
      "        [-0.4812,  0.6380, -0.3210,  3.3194,  3.4126],\n",
      "        [-0.2758,  2.0066,  0.1340,  1.1702,  3.1479],\n",
      "        [-0.4240,  2.0175,  0.1842,  1.1885,  6.1487],\n",
      "        [-0.8057,  1.9366,  0.3069,  1.8151,  5.3195],\n",
      "        [-0.4894,  1.2801, -0.5092, -0.4981,  4.6085],\n",
      "        [-0.6104,  2.1367,  0.5021,  0.5647,  3.6386],\n",
      "        [-1.1190,  2.8802,  0.9728,  0.4850,  3.8516],\n",
      "        [-0.5492,  1.6251,  0.1781,  0.3810,  3.5698],\n",
      "        [-0.3504,  1.7929,  0.1763,  0.8339,  5.4459],\n",
      "        [-0.1979,  1.1210, -0.0209,  1.3253,  4.5310],\n",
      "        [-0.5741,  1.1098, -0.3419,  1.3708,  4.2611],\n",
      "        [-0.4698,  1.6897,  0.1669,  0.2075,  3.7040],\n",
      "        [-0.4020,  1.8461,  0.2136,  1.5007,  5.4406],\n",
      "        [-0.4453,  2.3706,  0.5034, -0.1774,  4.1750],\n",
      "        [-0.5543,  0.1356, -0.9228,  1.8409,  3.1067],\n",
      "        [-0.5623,  2.5885,  0.3282, -1.3730,  3.9058],\n",
      "        [-1.1742,  2.4951,  0.7818,  0.3225,  5.0899],\n",
      "        [-0.3857,  1.2553,  0.0632,  2.5052,  4.1538],\n",
      "        [-0.6482,  1.7628, -0.0489,  0.2679,  4.5894],\n",
      "        [-1.0071,  2.6381, -0.0632, -0.5686,  6.0639],\n",
      "        [-0.5402,  2.4785,  0.2732, -1.0259,  4.9116],\n",
      "        [-0.3971,  1.2038, -0.1766,  0.0644,  3.3699],\n",
      "        [-0.4990,  0.6459, -0.4215,  2.1872,  3.8398],\n",
      "        [-0.6655,  2.4601,  0.3206, -0.2431,  3.9260],\n",
      "        [-0.5508,  1.4342, -0.1775,  0.2202,  4.0706],\n",
      "        [-0.5623,  1.8947,  0.4718,  0.0873,  3.1395],\n",
      "        [-0.7800,  2.4861,  0.5924,  0.1555,  4.3204],\n",
      "        [-0.2497,  1.1955,  0.2557,  0.4774,  2.7790],\n",
      "        [-0.4798,  1.8315,  0.3468,  0.4751,  4.2067],\n",
      "        [-0.7234,  2.0775,  0.1085,  0.1872,  4.9331],\n",
      "        [-0.2462,  1.0035, -0.1787,  1.2310,  4.1485],\n",
      "        [-0.8154,  1.8007, -0.2770,  1.0203,  5.6931],\n",
      "        [-0.6701,  2.3673,  0.4797,  1.3115,  4.2072],\n",
      "        [-0.5483,  2.0225,  0.3404,  0.0866,  3.8292],\n",
      "        [-0.6524,  1.6688,  0.3679,  2.7552,  4.8808],\n",
      "        [-0.3477,  1.5752,  0.2425,  1.2988,  3.4430],\n",
      "        [-0.5705,  2.0645,  0.2650, -0.0223,  4.8219],\n",
      "        [-0.3877,  1.9882,  0.3343,  0.0195,  4.7710],\n",
      "        [-0.7715,  1.8983,  0.4196,  0.2593,  3.1398],\n",
      "        [-0.4595,  1.7137,  0.0168, -0.2424,  4.0103],\n",
      "        [-0.4476,  2.1938,  0.0512, -1.3847,  3.8489],\n",
      "        [-0.5457,  1.7166,  0.1749,  0.6660,  4.2284],\n",
      "        [-0.4536,  2.1247,  0.3127, -1.2248,  3.5423],\n",
      "        [-0.2662,  1.0984,  0.1700,  0.7066,  2.9999],\n",
      "        [-0.2281,  1.7804,  0.3315,  0.1186,  2.8665]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.4669, 0.9187, 0.5881, 0.3504, 0.9509],\n",
      "        [0.3583, 0.8978, 0.5839, 0.3371, 0.9853],\n",
      "        [0.3968, 0.9445, 0.5650, 0.3080, 0.9785],\n",
      "        [0.2439, 0.9666, 0.7254, 0.2220, 0.9773],\n",
      "        [0.3788, 0.9053, 0.5733, 0.3343, 0.9893],\n",
      "        [0.4043, 0.7949, 0.5176, 0.4898, 0.9610],\n",
      "        [0.4710, 0.7180, 0.4689, 0.7223, 0.9800],\n",
      "        [0.3720, 0.9062, 0.6563, 0.3066, 0.9608],\n",
      "        [0.4571, 0.7133, 0.5356, 0.7643, 0.9269],\n",
      "        [0.2680, 0.9477, 0.6691, 0.5670, 0.9911],\n",
      "        [0.4347, 0.7737, 0.5576, 0.5614, 0.9398],\n",
      "        [0.3670, 0.8321, 0.4601, 0.4514, 0.9829],\n",
      "        [0.4040, 0.8848, 0.5577, 0.4243, 0.9532],\n",
      "        [0.3539, 0.8621, 0.4766, 0.3012, 0.9823],\n",
      "        [0.3684, 0.8607, 0.5016, 0.3962, 0.9845],\n",
      "        [0.3055, 0.9258, 0.5501, 0.2967, 0.9886],\n",
      "        [0.3687, 0.8870, 0.6109, 0.7024, 0.9785],\n",
      "        [0.4070, 0.9249, 0.6461, 0.1941, 0.9869],\n",
      "        [0.3337, 0.8849, 0.5795, 0.5973, 0.9865],\n",
      "        [0.3820, 0.6543, 0.4204, 0.9651, 0.9681],\n",
      "        [0.4315, 0.8815, 0.5335, 0.7632, 0.9588],\n",
      "        [0.3956, 0.8826, 0.5459, 0.7665, 0.9979],\n",
      "        [0.3088, 0.8740, 0.5761, 0.8600, 0.9951],\n",
      "        [0.3800, 0.7825, 0.3754, 0.3780, 0.9901],\n",
      "        [0.3520, 0.8944, 0.6230, 0.6376, 0.9744],\n",
      "        [0.2462, 0.9469, 0.7257, 0.6189, 0.9792],\n",
      "        [0.3660, 0.8355, 0.5444, 0.5941, 0.9726],\n",
      "        [0.4133, 0.8573, 0.5440, 0.6972, 0.9957],\n",
      "        [0.4507, 0.7542, 0.4948, 0.7901, 0.9893],\n",
      "        [0.3603, 0.7521, 0.4154, 0.7975, 0.9861],\n",
      "        [0.3847, 0.8442, 0.5416, 0.5517, 0.9760],\n",
      "        [0.4008, 0.8637, 0.5532, 0.8177, 0.9957],\n",
      "        [0.3905, 0.9146, 0.6233, 0.4558, 0.9849],\n",
      "        [0.3649, 0.5338, 0.2844, 0.8631, 0.9572],\n",
      "        [0.3630, 0.9301, 0.5813, 0.2021, 0.9803],\n",
      "        [0.2361, 0.9238, 0.6861, 0.5799, 0.9939],\n",
      "        [0.4048, 0.7782, 0.5158, 0.9245, 0.9845],\n",
      "        [0.3434, 0.8536, 0.4878, 0.5666, 0.9899],\n",
      "        [0.2676, 0.9333, 0.4842, 0.3615, 0.9977],\n",
      "        [0.3681, 0.9226, 0.5679, 0.2639, 0.9927],\n",
      "        [0.4020, 0.7692, 0.4560, 0.5161, 0.9668],\n",
      "        [0.3778, 0.6561, 0.3962, 0.8991, 0.9790],\n",
      "        [0.3395, 0.9213, 0.5795, 0.4395, 0.9807],\n",
      "        [0.3657, 0.8076, 0.4557, 0.5548, 0.9832],\n",
      "        [0.3630, 0.8693, 0.6158, 0.5218, 0.9585],\n",
      "        [0.3143, 0.9232, 0.6439, 0.5388, 0.9869],\n",
      "        [0.4379, 0.7677, 0.5636, 0.6171, 0.9415],\n",
      "        [0.3823, 0.8619, 0.5858, 0.6166, 0.9853],\n",
      "        [0.3267, 0.8887, 0.5271, 0.5467, 0.9928],\n",
      "        [0.4388, 0.7318, 0.4554, 0.7740, 0.9845],\n",
      "        [0.3067, 0.8582, 0.4312, 0.7350, 0.9966],\n",
      "        [0.3385, 0.9143, 0.6177, 0.7878, 0.9853],\n",
      "        [0.3663, 0.8831, 0.5843, 0.5216, 0.9787],\n",
      "        [0.3425, 0.8414, 0.5910, 0.9402, 0.9925],\n",
      "        [0.4139, 0.8285, 0.5603, 0.7856, 0.9690],\n",
      "        [0.3611, 0.8874, 0.5659, 0.4944, 0.9920],\n",
      "        [0.4043, 0.8796, 0.5828, 0.5049, 0.9916],\n",
      "        [0.3161, 0.8697, 0.6034, 0.5645, 0.9585],\n",
      "        [0.3871, 0.8473, 0.5042, 0.4397, 0.9822],\n",
      "        [0.3899, 0.8997, 0.5128, 0.2003, 0.9791],\n",
      "        [0.3669, 0.8477, 0.5436, 0.6606, 0.9856],\n",
      "        [0.3885, 0.8933, 0.5775, 0.2271, 0.9719],\n",
      "        [0.4338, 0.7500, 0.5424, 0.6697, 0.9526],\n",
      "        [0.4432, 0.8557, 0.5821, 0.5296, 0.9462]], grad_fn=<SigmoidBackward0>)\n",
      "torch.Size([64, 5])\n",
      "tensor([[-2.5035e-01,  1.4541e+00,  2.1203e-01,  7.4773e-01,  3.6776e+00],\n",
      "        [-1.1607e-01,  9.3451e-01, -1.2458e-01,  9.5582e-01,  3.8905e+00],\n",
      "        [-3.1112e-01,  1.9410e+00,  3.4306e-02, -1.4935e+00,  2.7809e+00],\n",
      "        [-3.4542e-01,  2.1707e+00,  4.2087e-01, -1.4892e-03,  2.8569e+00],\n",
      "        [-1.6056e+00,  3.1773e+00, -1.1432e+00, -1.9041e+00,  2.2199e+00],\n",
      "        [-5.5661e-01,  1.2461e+00,  2.9168e-01,  2.2466e+00,  3.7176e+00],\n",
      "        [-7.6058e-01,  2.8432e+00,  5.7595e-01, -3.0271e-01,  4.0836e+00],\n",
      "        [-5.2833e-01,  1.3180e+00, -5.4528e-01,  7.0834e-02,  4.3469e+00],\n",
      "        [-6.5052e-01,  2.1392e+00,  4.8017e-02, -1.5177e-01,  5.1799e+00],\n",
      "        [-9.3891e-01,  2.6426e+00,  5.6432e-01,  3.7919e-01,  5.0539e+00],\n",
      "        [-1.0892e+00,  2.7546e+00,  9.7395e-01,  2.5602e-01,  3.4387e+00],\n",
      "        [-5.5082e-01,  1.4342e+00, -1.7748e-01,  2.2019e-01,  4.0706e+00],\n",
      "        [-2.6493e-01,  1.4757e+00, -3.1625e-02,  9.6640e-02,  3.0840e+00],\n",
      "        [-1.3038e+00,  3.5044e+00,  1.1477e+00, -4.5886e-01,  3.9964e+00],\n",
      "        [-2.5962e-01,  8.1666e-01, -2.9250e-01,  3.5929e-01,  2.7298e+00],\n",
      "        [-1.1209e+00,  2.9343e+00,  9.4664e-01,  1.0697e+00,  4.7681e+00],\n",
      "        [-8.0388e-01,  2.9500e+00,  3.7679e-01, -9.4245e-01,  5.5412e+00],\n",
      "        [-5.3932e-01,  1.3733e+00, -1.5503e-01,  1.1585e+00,  4.4714e+00],\n",
      "        [-2.8854e-01,  1.4038e+00,  1.3140e-01,  1.8344e+00,  3.6348e+00],\n",
      "        [-3.0052e-01,  1.6438e+00,  1.5577e-01,  2.2571e-01,  3.7074e+00],\n",
      "        [-5.5735e-01,  8.4688e-03, -9.2193e-01,  2.3369e+00,  3.0511e+00],\n",
      "        [-5.8599e-01,  1.6829e+00, -3.5836e-01,  3.7465e-01,  5.4504e+00],\n",
      "        [-3.5247e-01,  1.6245e+00, -2.8081e-02,  9.1294e-01,  5.4035e+00],\n",
      "        [-5.0256e-01,  2.3372e+00,  2.7456e-01,  4.7263e-01,  3.7251e+00],\n",
      "        [-1.9013e-01,  1.2917e+00,  8.0318e-02,  9.0800e-01,  2.8589e+00],\n",
      "        [-4.2184e-01,  1.5618e+00,  3.0759e-02,  3.5754e-01,  3.7602e+00],\n",
      "        [-6.5542e-01,  1.3250e+00, -7.7831e-01, -6.5161e-01,  4.5635e+00],\n",
      "        [-5.4229e-01,  9.9897e-01, -5.9003e-01, -9.0018e-01,  3.2036e+00],\n",
      "        [-2.7829e-01,  8.1202e-01, -6.8540e-01,  3.5667e-01,  2.3379e+00],\n",
      "        [-7.5736e-02,  1.9879e+00,  1.4609e-01, -4.4451e-01,  2.5882e+00],\n",
      "        [-7.1366e-01,  2.4419e+00,  6.9537e-02,  5.1106e-01,  6.5454e+00],\n",
      "        [-5.7859e-01,  7.7671e-01, -8.7686e-03,  2.8402e+00,  3.4363e+00],\n",
      "        [-1.1355e+00,  2.5716e+00,  7.0857e-01,  8.1813e-01,  4.2146e+00],\n",
      "        [-8.4619e-01,  3.3691e+00,  7.8893e-01, -7.2903e-01,  3.8685e+00],\n",
      "        [-4.0026e-01,  1.9355e+00,  1.8955e-01,  6.7658e-01,  4.4941e+00],\n",
      "        [-9.1506e-01,  3.2869e+00,  4.4700e-01, -4.8279e-01,  3.0025e+00],\n",
      "        [-2.7575e-01,  2.0066e+00,  1.3401e-01,  1.1702e+00,  3.1479e+00],\n",
      "        [-6.1093e-01,  2.0983e+00,  4.2917e-01,  5.6985e-01,  3.4858e+00],\n",
      "        [-1.0242e+00,  2.4506e+00,  5.1970e-01,  6.6294e-01,  4.4442e+00],\n",
      "        [-5.1419e-01,  2.2145e+00,  4.1594e-01, -5.5619e-01,  3.5148e+00],\n",
      "        [-4.7639e-01,  1.5559e+00, -1.3590e-02,  4.5970e-01,  4.2554e+00],\n",
      "        [-5.7214e-01,  1.3067e+00, -2.1867e-01,  1.6322e+00,  4.6047e+00],\n",
      "        [-4.2401e-01,  2.0175e+00,  1.8419e-01,  1.1885e+00,  6.1487e+00],\n",
      "        [-3.8922e-01,  1.4420e+00,  1.6184e-01,  3.5057e-03,  3.3517e+00],\n",
      "        [-9.3353e-01,  2.4357e+00,  5.1732e-01,  1.3311e-01,  3.5801e+00],\n",
      "        [-5.1248e-01,  1.7428e+00,  1.0719e-01, -8.6976e-02,  3.9615e+00],\n",
      "        [-5.3405e-01,  2.2385e+00,  4.0263e-01, -6.7210e-01,  3.8951e+00],\n",
      "        [-3.0563e-01,  1.6432e+00, -3.5198e-01, -1.9998e+00,  2.5893e+00],\n",
      "        [-4.5358e-01,  2.1247e+00,  3.1272e-01, -1.2248e+00,  3.5423e+00],\n",
      "        [-4.3630e-01,  1.5747e+00,  3.9630e-01,  2.4181e-01,  2.8319e+00],\n",
      "        [-6.1042e-01,  2.1367e+00,  5.0212e-01,  5.6475e-01,  3.6386e+00],\n",
      "        [-3.1112e-01,  1.7169e+00,  1.2865e-01,  1.3034e+00,  4.5304e+00],\n",
      "        [-1.5560e-01,  1.4178e+00, -3.7273e-01,  1.1670e+00,  2.5245e+00],\n",
      "        [-3.9260e-01,  2.0538e+00,  2.0594e-01, -6.3418e-01,  3.8776e+00],\n",
      "        [-8.1676e-01,  2.6670e+00,  2.3828e-01, -5.7790e-01,  3.9102e+00],\n",
      "        [-5.1236e-01,  1.8430e+00, -5.3357e-02,  8.6241e-01,  5.6565e+00],\n",
      "        [-1.1742e+00,  2.4951e+00,  7.8178e-01,  3.2254e-01,  5.0899e+00],\n",
      "        [-5.7909e-01,  2.1973e+00,  5.2269e-01,  8.7659e-01,  4.4273e+00],\n",
      "        [-5.0428e-01,  1.7121e+00, -7.6997e-02, -2.7226e-01,  4.1809e+00],\n",
      "        [-2.4688e-01,  5.4266e-01, -4.3615e-01,  5.8002e-01,  2.3883e+00],\n",
      "        [-5.6917e-01,  2.1826e+00,  4.6131e-01,  3.9728e-01,  5.0225e+00],\n",
      "        [-6.7362e-01,  2.1090e+00,  4.6120e-02, -2.4392e-01,  4.9749e+00],\n",
      "        [-4.5144e-01,  2.7029e+00, -9.3146e-02, -5.0358e-01,  4.1464e+00],\n",
      "        [-7.9074e-01,  5.3776e-01, -1.3128e+00,  1.4021e+00,  4.5478e+00]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.4377, 0.8106, 0.5528, 0.6787, 0.9753],\n",
      "        [0.4710, 0.7180, 0.4689, 0.7223, 0.9800],\n",
      "        [0.4228, 0.8745, 0.5086, 0.1834, 0.9416],\n",
      "        [0.4145, 0.8976, 0.6037, 0.4996, 0.9457],\n",
      "        [0.1672, 0.9600, 0.2417, 0.1296, 0.9020],\n",
      "        [0.3643, 0.7766, 0.5724, 0.9044, 0.9763],\n",
      "        [0.3185, 0.9450, 0.6401, 0.4249, 0.9834],\n",
      "        [0.3709, 0.7888, 0.3670, 0.5177, 0.9872],\n",
      "        [0.3429, 0.8947, 0.5120, 0.4621, 0.9944],\n",
      "        [0.2811, 0.9336, 0.6375, 0.5937, 0.9937],\n",
      "        [0.2518, 0.9402, 0.7259, 0.5637, 0.9689],\n",
      "        [0.3657, 0.8076, 0.4557, 0.5548, 0.9832],\n",
      "        [0.4342, 0.8139, 0.4921, 0.5241, 0.9562],\n",
      "        [0.2135, 0.9708, 0.7591, 0.3873, 0.9820],\n",
      "        [0.4355, 0.6935, 0.4274, 0.5889, 0.9388],\n",
      "        [0.2458, 0.9495, 0.7204, 0.7445, 0.9916],\n",
      "        [0.3092, 0.9503, 0.5931, 0.2804, 0.9961],\n",
      "        [0.3683, 0.7979, 0.4613, 0.7611, 0.9887],\n",
      "        [0.4284, 0.8028, 0.5328, 0.8623, 0.9743],\n",
      "        [0.4254, 0.8380, 0.5389, 0.5562, 0.9760],\n",
      "        [0.3642, 0.5021, 0.2846, 0.9119, 0.9548],\n",
      "        [0.3576, 0.8433, 0.4114, 0.5926, 0.9957],\n",
      "        [0.4128, 0.8354, 0.4930, 0.7136, 0.9955],\n",
      "        [0.3769, 0.9119, 0.5682, 0.6160, 0.9765],\n",
      "        [0.4526, 0.7844, 0.5201, 0.7126, 0.9458],\n",
      "        [0.3961, 0.8266, 0.5077, 0.5884, 0.9772],\n",
      "        [0.3418, 0.7900, 0.3147, 0.3426, 0.9897],\n",
      "        [0.3677, 0.7309, 0.3566, 0.2890, 0.9610],\n",
      "        [0.4309, 0.6925, 0.3351, 0.5882, 0.9120],\n",
      "        [0.4811, 0.8795, 0.5365, 0.3907, 0.9301],\n",
      "        [0.3288, 0.9200, 0.5174, 0.6251, 0.9986],\n",
      "        [0.3593, 0.6850, 0.4978, 0.9448, 0.9688],\n",
      "        [0.2431, 0.9290, 0.6701, 0.6938, 0.9854],\n",
      "        [0.3002, 0.9667, 0.6876, 0.3254, 0.9795],\n",
      "        [0.4013, 0.8739, 0.5472, 0.6630, 0.9889],\n",
      "        [0.2860, 0.9640, 0.6099, 0.3816, 0.9527],\n",
      "        [0.4315, 0.8815, 0.5335, 0.7632, 0.9588],\n",
      "        [0.3518, 0.8907, 0.6057, 0.6387, 0.9703],\n",
      "        [0.2642, 0.9206, 0.6271, 0.6599, 0.9884],\n",
      "        [0.3742, 0.9015, 0.6025, 0.3644, 0.9711],\n",
      "        [0.3831, 0.8258, 0.4966, 0.6129, 0.9860],\n",
      "        [0.3607, 0.7870, 0.4455, 0.8365, 0.9901],\n",
      "        [0.3956, 0.8826, 0.5459, 0.7665, 0.9979],\n",
      "        [0.4039, 0.8088, 0.5404, 0.5009, 0.9662],\n",
      "        [0.2822, 0.9195, 0.6265, 0.5332, 0.9729],\n",
      "        [0.3746, 0.8510, 0.5268, 0.4783, 0.9813],\n",
      "        [0.3696, 0.9037, 0.5993, 0.3380, 0.9801],\n",
      "        [0.4242, 0.8380, 0.4129, 0.1192, 0.9302],\n",
      "        [0.3885, 0.8933, 0.5775, 0.2271, 0.9719],\n",
      "        [0.3926, 0.8285, 0.5978, 0.5602, 0.9444],\n",
      "        [0.3520, 0.8944, 0.6230, 0.6376, 0.9744],\n",
      "        [0.4228, 0.8477, 0.5321, 0.7864, 0.9893],\n",
      "        [0.4612, 0.8050, 0.4079, 0.7626, 0.9258],\n",
      "        [0.4031, 0.8863, 0.5513, 0.3466, 0.9797],\n",
      "        [0.3065, 0.9351, 0.5593, 0.3594, 0.9804],\n",
      "        [0.3746, 0.8633, 0.4867, 0.7032, 0.9965],\n",
      "        [0.2361, 0.9238, 0.6861, 0.5799, 0.9939],\n",
      "        [0.3591, 0.9000, 0.6278, 0.7061, 0.9882],\n",
      "        [0.3765, 0.8471, 0.4808, 0.4324, 0.9849],\n",
      "        [0.4386, 0.6324, 0.3927, 0.6411, 0.9159],\n",
      "        [0.3614, 0.8987, 0.6133, 0.5980, 0.9935],\n",
      "        [0.3377, 0.8918, 0.5115, 0.4393, 0.9931],\n",
      "        [0.3890, 0.9372, 0.4767, 0.3767, 0.9844],\n",
      "        [0.3120, 0.6313, 0.2120, 0.8025, 0.9895]], grad_fn=<SigmoidBackward0>)\n",
      "torch.Size([64, 5])\n"
     ]
    }
   ],
   "source": [
    "def train(train_loader, X_test, y_test, model, loss, num_epochs, batch_size,\n",
    "          optimizer):\n",
    "    batch_count = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n = 0.0, 0.0, 0\n",
    "        for X, y in train_loader:\n",
    "            pred = model(X)\n",
    "            print(pred)\n",
    "            print(pred.shape)\n",
    "            return\n",
    "            l = loss(pred, y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += sum(row.all().int().item()\n",
    "                                 for row in (pred.ge(0.5) == y))\n",
    "            n += y.shape[0]\n",
    "            batch_count += 1\n",
    "        test_acc = evaluate_accuracy(X_test, y_test, model)\n",
    "        print(\n",
    "            'epoch %d, loss %.4f, train acc %.3f, test acc %.3f'\n",
    "            % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n,\n",
    "               test_acc))\n",
    "\n",
    "\n",
    "num_epochs, batch_size = 20, 358\n",
    "train(train_loader, X_test, y_test, model, loss, num_epochs, batch_size, optimizer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
