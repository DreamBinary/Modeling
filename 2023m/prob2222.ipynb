{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T10:36:23.747332Z",
     "iopub.status.busy": "2023-02-18T10:36:23.746983Z",
     "iopub.status.idle": "2023-02-18T10:36:25.161170Z",
     "shell.execute_reply": "2023-02-18T10:36:25.160623Z",
     "shell.execute_reply.started": "2023-02-18T10:36:23.747250Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     Unnamed: 0       Date  Contest number   Word  \\\n0             0 2022-01-07             202  slump   \n1             1 2022-01-08             203  crank   \n2             2 2022-01-09             204  gorge   \n3             3 2022-01-10             205  query   \n4             4 2022-01-11             206  drink   \n..          ...        ...             ...    ...   \n350         350 2022-12-27             556  condo   \n351         351 2022-12-28             557  impel   \n352         352 2022-12-29             558  havoc   \n353         353 2022-12-30             559  molar   \n354         354 2022-12-31             560  manly   \n\n     Number of  reported results  Number in hard mode  1 try  2 tries  \\\n0                          80630                 1362      1        3   \n1                         101503                 1763      1        5   \n2                          91477                 1913      1        3   \n3                         107134                 2242      1        4   \n4                         153880                 3017      1        9   \n..                           ...                  ...    ...      ...   \n350                        20879                 2012      0        2   \n351                        20160                 1937      0        3   \n352                        20001                 1919      0        2   \n353                        21204                 1973      0        4   \n354                        20380                 1899      0        2   \n\n     3 tries  4 tries  5 tries  6 tries  7 or more tries (X)     ratio  vowel  \\\n0         23       39       24        9                    1  0.016892      1   \n1         23       31       24       14                    2  0.017369      1   \n2         13       27       30       22                    4  0.020912      2   \n3         16       30       30       17                    2  0.020927      2   \n4         35       34       16        5                    1  0.019606      1   \n..       ...      ...      ...      ...                  ...       ...    ...   \n350       17       35       29       14                    3  0.096365      2   \n351       21       40       25        9                    1  0.096081      2   \n352       16       38       30       12                    2  0.095945      2   \n353       21       38       26        9                    1  0.093048      2   \n354       17       37       29       12                    2  0.093180      1   \n\n     len  uniq  star  \n0      5     5   NaN  \n1      5     5   NaN  \n2      5     4   NaN  \n3      5     5   NaN  \n4      5     5   NaN  \n..   ...   ...   ...  \n350    5     4   NaN  \n351    5     5   NaN  \n352    5     5   NaN  \n353    5     5   NaN  \n354    5     5   NaN  \n\n[355 rows x 18 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Date</th>\n      <th>Contest number</th>\n      <th>Word</th>\n      <th>Number of  reported results</th>\n      <th>Number in hard mode</th>\n      <th>1 try</th>\n      <th>2 tries</th>\n      <th>3 tries</th>\n      <th>4 tries</th>\n      <th>5 tries</th>\n      <th>6 tries</th>\n      <th>7 or more tries (X)</th>\n      <th>ratio</th>\n      <th>vowel</th>\n      <th>len</th>\n      <th>uniq</th>\n      <th>star</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2022-01-07</td>\n      <td>202</td>\n      <td>slump</td>\n      <td>80630</td>\n      <td>1362</td>\n      <td>1</td>\n      <td>3</td>\n      <td>23</td>\n      <td>39</td>\n      <td>24</td>\n      <td>9</td>\n      <td>1</td>\n      <td>0.016892</td>\n      <td>1</td>\n      <td>5</td>\n      <td>5</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2022-01-08</td>\n      <td>203</td>\n      <td>crank</td>\n      <td>101503</td>\n      <td>1763</td>\n      <td>1</td>\n      <td>5</td>\n      <td>23</td>\n      <td>31</td>\n      <td>24</td>\n      <td>14</td>\n      <td>2</td>\n      <td>0.017369</td>\n      <td>1</td>\n      <td>5</td>\n      <td>5</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2022-01-09</td>\n      <td>204</td>\n      <td>gorge</td>\n      <td>91477</td>\n      <td>1913</td>\n      <td>1</td>\n      <td>3</td>\n      <td>13</td>\n      <td>27</td>\n      <td>30</td>\n      <td>22</td>\n      <td>4</td>\n      <td>0.020912</td>\n      <td>2</td>\n      <td>5</td>\n      <td>4</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2022-01-10</td>\n      <td>205</td>\n      <td>query</td>\n      <td>107134</td>\n      <td>2242</td>\n      <td>1</td>\n      <td>4</td>\n      <td>16</td>\n      <td>30</td>\n      <td>30</td>\n      <td>17</td>\n      <td>2</td>\n      <td>0.020927</td>\n      <td>2</td>\n      <td>5</td>\n      <td>5</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2022-01-11</td>\n      <td>206</td>\n      <td>drink</td>\n      <td>153880</td>\n      <td>3017</td>\n      <td>1</td>\n      <td>9</td>\n      <td>35</td>\n      <td>34</td>\n      <td>16</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0.019606</td>\n      <td>1</td>\n      <td>5</td>\n      <td>5</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>350</th>\n      <td>350</td>\n      <td>2022-12-27</td>\n      <td>556</td>\n      <td>condo</td>\n      <td>20879</td>\n      <td>2012</td>\n      <td>0</td>\n      <td>2</td>\n      <td>17</td>\n      <td>35</td>\n      <td>29</td>\n      <td>14</td>\n      <td>3</td>\n      <td>0.096365</td>\n      <td>2</td>\n      <td>5</td>\n      <td>4</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>351</th>\n      <td>351</td>\n      <td>2022-12-28</td>\n      <td>557</td>\n      <td>impel</td>\n      <td>20160</td>\n      <td>1937</td>\n      <td>0</td>\n      <td>3</td>\n      <td>21</td>\n      <td>40</td>\n      <td>25</td>\n      <td>9</td>\n      <td>1</td>\n      <td>0.096081</td>\n      <td>2</td>\n      <td>5</td>\n      <td>5</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>352</th>\n      <td>352</td>\n      <td>2022-12-29</td>\n      <td>558</td>\n      <td>havoc</td>\n      <td>20001</td>\n      <td>1919</td>\n      <td>0</td>\n      <td>2</td>\n      <td>16</td>\n      <td>38</td>\n      <td>30</td>\n      <td>12</td>\n      <td>2</td>\n      <td>0.095945</td>\n      <td>2</td>\n      <td>5</td>\n      <td>5</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>353</th>\n      <td>353</td>\n      <td>2022-12-30</td>\n      <td>559</td>\n      <td>molar</td>\n      <td>21204</td>\n      <td>1973</td>\n      <td>0</td>\n      <td>4</td>\n      <td>21</td>\n      <td>38</td>\n      <td>26</td>\n      <td>9</td>\n      <td>1</td>\n      <td>0.093048</td>\n      <td>2</td>\n      <td>5</td>\n      <td>5</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>354</th>\n      <td>354</td>\n      <td>2022-12-31</td>\n      <td>560</td>\n      <td>manly</td>\n      <td>20380</td>\n      <td>1899</td>\n      <td>0</td>\n      <td>2</td>\n      <td>17</td>\n      <td>37</td>\n      <td>29</td>\n      <td>12</td>\n      <td>2</td>\n      <td>0.093180</td>\n      <td>1</td>\n      <td>5</td>\n      <td>5</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>355 rows × 18 columns</p>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"data2.xlsx\", header=0)\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-02-18T10:36:25.162526Z",
     "iopub.status.busy": "2023-02-18T10:36:25.162290Z",
     "iopub.status.idle": "2023-02-18T10:36:25.167609Z",
     "shell.execute_reply": "2023-02-18T10:36:25.167209Z",
     "shell.execute_reply.started": "2023-02-18T10:36:25.162510Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "355"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(df[df[\"len\"] == 4].index.values)\n",
    "df = df.drop(df[df[\"len\"] == 6].index.values)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-02-18T10:36:25.168342Z",
     "iopub.status.busy": "2023-02-18T10:36:25.168147Z",
     "iopub.status.idle": "2023-02-18T10:36:25.172201Z",
     "shell.execute_reply": "2023-02-18T10:36:25.171810Z",
     "shell.execute_reply.started": "2023-02-18T10:36:25.168327Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'a': 0,\n 'b': 1,\n 'c': 2,\n 'd': 3,\n 'e': 4,\n 'f': 5,\n 'g': 6,\n 'h': 7,\n 'i': 8,\n 'j': 9,\n 'k': 10,\n 'l': 11,\n 'm': 12,\n 'n': 13,\n 'o': 14,\n 'p': 15,\n 'q': 16,\n 'r': 17,\n 's': 18,\n 't': 19,\n 'u': 20,\n 'v': 21,\n 'w': 22,\n 'x': 23,\n 'y': 24,\n 'z': 25,\n 'ï': 8}"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = {j: i\n",
    "       for i, j in enumerate('abcdefghijklmnopqrstuvwxyz', 0)}\n",
    "dic[\"ï\"] = dic[\"i\"]\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-02-18T10:36:25.172925Z",
     "iopub.status.busy": "2023-02-18T10:36:25.172731Z",
     "iopub.status.idle": "2023-02-18T10:36:25.194892Z",
     "shell.execute_reply": "2023-02-18T10:36:25.194492Z",
     "shell.execute_reply.started": "2023-02-18T10:36:25.172909Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[[18, 11, 20, 12, 15],\n [2, 17, 0, 13, 10],\n [6, 14, 17, 6, 4],\n [16, 20, 4, 17, 24],\n [3, 17, 8, 13, 10],\n [0, 1, 1, 4, 24],\n [19, 0, 13, 6, 24],\n [15, 0, 13, 8, 2],\n [18, 14, 11, 0, 17],\n [18, 7, 8, 17, 4],\n [15, 17, 14, 23, 24],\n [15, 14, 8, 13, 19],\n [17, 14, 1, 14, 19],\n [15, 17, 8, 2, 10],\n [22, 8, 13, 2, 4],\n [2, 17, 8, 12, 15],\n [10, 13, 14, 11, 11],\n [18, 20, 6, 0, 17],\n [22, 7, 0, 2, 10],\n [12, 14, 20, 13, 19],\n [15, 4, 17, 10, 24],\n [2, 14, 20, 11, 3],\n [22, 17, 20, 13, 6],\n [11, 8, 6, 7, 19],\n [19, 7, 14, 18, 4],\n [12, 14, 8, 18, 19],\n [18, 7, 0, 17, 3],\n [15, 11, 4, 0, 19],\n [0, 11, 14, 5, 19],\n [18, 10, 8, 11, 11],\n [4, 11, 3, 4, 17],\n [5, 17, 0, 12, 4],\n [7, 20, 12, 14, 17],\n [15, 0, 20, 18, 4],\n [20, 11, 2, 4, 17],\n [20, 11, 19, 17, 0],\n [17, 14, 1, 8, 13],\n [2, 24, 13, 8, 2],\n [0, 17, 14, 12, 0],\n [2, 0, 20, 11, 10],\n [18, 7, 0, 10, 4],\n [3, 14, 3, 6, 4],\n [18, 22, 8, 11, 11],\n [19, 0, 2, 8, 19],\n [14, 19, 7, 4, 17],\n [19, 7, 14, 17, 13],\n [19, 17, 14, 21, 4],\n [1, 11, 14, 10, 4],\n [21, 8, 21, 8, 3],\n [18, 15, 8, 11, 11],\n [2, 7, 0, 13, 19],\n [2, 7, 14, 10, 4],\n [17, 20, 15, 4, 4],\n [13, 0, 18, 19, 24],\n [12, 14, 20, 17, 13],\n [0, 7, 4, 0, 3],\n [1, 17, 8, 13, 4],\n [2, 11, 14, 19, 7],\n [7, 14, 0, 17, 3],\n [18, 22, 4, 4, 19],\n [12, 14, 13, 19, 7],\n [11, 0, 15, 18, 4],\n [22, 0, 19, 2, 7],\n [19, 14, 3, 0, 24],\n [5, 14, 2, 20, 18],\n [18, 12, 4, 11, 19],\n [19, 4, 0, 18, 4],\n [2, 0, 19, 4, 17],\n [12, 14, 21, 8, 4],\n [18, 0, 20, 19, 4],\n [0, 11, 11, 14, 22],\n [17, 4, 13, 4, 22],\n [19, 7, 4, 8, 17],\n [18, 11, 14, 18, 7],\n [15, 20, 17, 6, 4],\n [2, 7, 4, 18, 19],\n [3, 4, 15, 14, 19],\n [4, 15, 14, 23, 24],\n [13, 24, 12, 15, 7],\n [5, 14, 20, 13, 3],\n [18, 7, 0, 11, 11],\n [18, 19, 14, 21, 4],\n [11, 14, 22, 11, 24],\n [18, 13, 14, 20, 19],\n [19, 17, 14, 15, 4],\n [5, 4, 22, 4, 17],\n [18, 7, 0, 22, 11],\n [13, 0, 19, 0, 11],\n [2, 14, 12, 12, 0],\n [5, 14, 17, 0, 24],\n [18, 2, 0, 17, 4],\n [18, 19, 0, 8, 17],\n [1, 11, 0, 2, 10],\n [18, 16, 20, 0, 3],\n [17, 14, 24, 0, 11],\n [2, 7, 20, 13, 10],\n [12, 8, 13, 2, 4],\n [18, 7, 0, 12, 4],\n [2, 7, 4, 4, 10],\n [0, 12, 15, 11, 4],\n [5, 11, 0, 8, 17],\n [5, 14, 24, 4, 17],\n [2, 0, 17, 6, 14],\n [14, 23, 8, 3, 4],\n [15, 11, 0, 13, 19],\n [14, 11, 8, 21, 4],\n [8, 13, 4, 17, 19],\n [0, 18, 10, 4, 22],\n [7, 4, 8, 18, 19],\n [18, 7, 14, 22, 13],\n [25, 4, 18, 19, 24],\n [11, 0, 17, 21, 0],\n [5, 14, 17, 6, 14],\n [18, 19, 14, 17, 24],\n [7, 0, 8, 17, 24],\n [19, 17, 0, 8, 13],\n [7, 14, 12, 4, 17],\n [1, 0, 3, 6, 4],\n [12, 8, 3, 18, 19],\n [2, 0, 13, 13, 24],\n [18, 7, 8, 13, 4],\n [6, 4, 2, 10, 14],\n [5, 0, 17, 2, 4],\n [18, 11, 20, 13, 6],\n [19, 8, 15, 18, 24],\n [12, 4, 19, 0, 11],\n [24, 8, 4, 11, 3],\n [3, 4, 11, 21, 4],\n [1, 4, 8, 13, 6],\n [18, 2, 14, 20, 17],\n [6, 11, 0, 18, 18],\n [6, 0, 12, 4, 17],\n [18, 2, 17, 0, 15],\n [12, 14, 13, 4, 24],\n [7, 8, 13, 6, 4],\n [0, 11, 1, 20, 12],\n [21, 14, 20, 2, 7],\n [0, 18, 18, 4, 19],\n [19, 8, 0, 17, 0],\n [2, 17, 4, 15, 19],\n [1, 0, 24, 14, 20],\n [0, 19, 14, 11, 11],\n [12, 0, 13, 14, 17],\n [2, 17, 4, 0, 10],\n [18, 7, 14, 22, 24],\n [15, 4, 0, 2, 7],\n [5, 17, 14, 19, 7],\n [3, 4, 15, 19, 7],\n [6, 11, 14, 14, 12],\n [5, 11, 14, 14, 3],\n [19, 17, 0, 8, 19],\n [6, 8, 17, 19, 7],\n [15, 8, 4, 19, 24],\n [6, 14, 14, 18, 4],\n [5, 11, 14, 0, 19],\n [3, 14, 13, 14, 17],\n [0, 19, 14, 13, 4],\n [15, 17, 8, 12, 14],\n [0, 15, 17, 14, 13],\n [1, 11, 14, 22, 13],\n [2, 0, 2, 0, 14],\n [11, 14, 18, 4, 17],\n [8, 13, 15, 20, 19],\n [6, 11, 14, 0, 19],\n [0, 22, 5, 20, 11],\n [1, 17, 8, 13, 10],\n [18, 12, 8, 19, 4],\n [1, 4, 0, 3, 24],\n [17, 20, 18, 19, 24],\n [17, 4, 19, 17, 14],\n [3, 17, 14, 11, 11],\n [6, 0, 22, 10, 24],\n [7, 20, 19, 2, 7],\n [15, 8, 13, 19, 14],\n [4, 6, 17, 4, 19],\n [11, 8, 11, 0, 2],\n [18, 4, 21, 4, 17],\n [5, 8, 4, 11, 3],\n [5, 11, 20, 5, 5],\n [0, 6, 0, 15, 4],\n [21, 14, 8, 2, 4],\n [18, 19, 4, 0, 3],\n [1, 4, 17, 19, 7],\n [12, 0, 3, 0, 12],\n [13, 8, 6, 7, 19],\n [1, 11, 0, 13, 3],\n [11, 8, 21, 4, 17],\n [22, 4, 3, 6, 4],\n [17, 14, 14, 12, 24],\n [22, 0, 2, 10, 24],\n [5, 11, 14, 2, 10],\n [0, 13, 6, 17, 24],\n [19, 17, 8, 19, 4],\n [0, 15, 7, 8, 3],\n [19, 17, 24, 18, 19],\n [12, 8, 3, 6, 4],\n [15, 14, 22, 4, 17],\n [4, 11, 14, 15, 4],\n [2, 8, 13, 2, 7],\n [12, 14, 19, 19, 14],\n [18, 19, 14, 12, 15],\n [20, 15, 18, 4, 19],\n [1, 11, 20, 5, 5],\n [2, 17, 0, 12, 15],\n [16, 20, 0, 17, 19],\n [2, 14, 24, 11, 24],\n [24, 14, 20, 19, 7],\n [17, 7, 24, 12, 4],\n [1, 20, 6, 6, 24],\n [0, 11, 8, 4, 13],\n [18, 12, 4, 0, 17],\n [20, 13, 5, 8, 19],\n [15, 0, 19, 19, 24],\n [2, 11, 8, 13, 6],\n [6, 11, 4, 0, 13],\n [11, 0, 1, 4, 11],\n [7, 20, 13, 10, 24],\n [10, 7, 0, 10, 8],\n [15, 14, 10, 4, 17],\n [6, 17, 20, 4, 11],\n [19, 22, 8, 2, 4],\n [19, 22, 0, 13, 6],\n [18, 7, 17, 20, 6],\n [19, 17, 4, 0, 19],\n [22, 0, 18, 19, 4],\n [12, 4, 17, 8, 19],\n [22, 14, 21, 4, 13],\n [13, 4, 4, 3, 24],\n [2, 11, 14, 22, 13],\n [8, 17, 14, 13, 24],\n [17, 20, 3, 4, 17],\n [6, 0, 20, 25, 4],\n [2, 7, 8, 4, 5],\n [14, 13, 18, 4, 19],\n [15, 17, 8, 25, 4],\n [5, 20, 13, 6, 8],\n [2, 7, 0, 17, 12],\n [6, 20, 11, 11, 24],\n [8, 13, 19, 4, 17],\n [22, 7, 14, 14, 15],\n [19, 0, 20, 13, 19],\n [11, 4, 4, 17, 24],\n [2, 11, 0, 18, 18],\n [19, 7, 4, 12, 4],\n [11, 14, 5, 19, 24],\n [19, 8, 1, 8, 0],\n [1, 14, 14, 25, 4],\n [0, 11, 15, 7, 0],\n [19, 7, 24, 12, 4],\n [3, 14, 20, 1, 19],\n [15, 0, 17, 4, 17],\n [2, 7, 20, 19, 4],\n [18, 19, 8, 2, 10],\n [19, 17, 8, 2, 4],\n [0, 11, 8, 10, 4],\n [17, 4, 2, 0, 15],\n [18, 0, 8, 13, 19],\n [6, 11, 14, 17, 24],\n [6, 17, 0, 19, 4],\n [0, 3, 12, 8, 19],\n [1, 17, 8, 18, 10],\n [18, 14, 6, 6, 24],\n [20, 18, 20, 17, 15],\n [18, 2, 0, 11, 3],\n [18, 2, 14, 17, 13],\n [11, 4, 0, 21, 4],\n [19, 22, 8, 13, 4],\n [18, 19, 8, 13, 6],\n [1, 14, 20, 6, 7],\n [12, 0, 17, 23, 7],\n [18, 11, 14, 19, 7],\n [3, 0, 13, 3, 24],\n [21, 8, 6, 14, 17],\n [7, 14, 22, 3, 24],\n [4, 13, 9, 14, 24],\n [21, 0, 11, 8, 3],\n [8, 14, 13, 8, 2],\n [4, 16, 20, 0, 11],\n [5, 11, 14, 14, 17],\n [2, 0, 19, 2, 7],\n [18, 15, 0, 3, 4],\n [18, 19, 4, 8, 13],\n [4, 23, 8, 18, 19],\n [16, 20, 8, 17, 10],\n [3, 4, 13, 8, 12],\n [6, 17, 14, 21, 4],\n [18, 15, 8, 4, 11],\n [12, 20, 12, 12, 24],\n [5, 0, 20, 11, 19],\n [5, 14, 6, 6, 24],\n [5, 11, 14, 20, 19],\n [2, 0, 17, 17, 24],\n [18, 13, 4, 0, 10],\n [11, 8, 1, 4, 11],\n [22, 0, 11, 19, 25],\n [0, 15, 19, 11, 24],\n [15, 8, 13, 4, 24],\n [8, 13, 4, 15, 19],\n [0, 11, 14, 20, 3],\n [15, 7, 14, 19, 14],\n [3, 17, 4, 0, 12],\n [18, 19, 0, 11, 4],\n [1, 4, 6, 8, 13],\n [18, 15, 4, 11, 11],\n [17, 0, 8, 13, 24],\n [20, 13, 8, 19, 4],\n [12, 4, 3, 0, 11],\n [21, 0, 11, 4, 19],\n [8, 13, 0, 13, 4],\n [12, 0, 15, 11, 4],\n [18, 13, 0, 17, 11],\n [1, 0, 10, 4, 17],\n [19, 7, 4, 17, 4],\n [6, 11, 24, 15, 7],\n [0, 21, 4, 17, 19],\n [1, 17, 0, 21, 4],\n [0, 23, 8, 14, 12],\n [15, 17, 8, 12, 4],\n [3, 17, 8, 21, 4],\n [5, 4, 0, 18, 19],\n [8, 19, 2, 7, 24],\n [7, 0, 15, 15, 24],\n [19, 4, 15, 8, 3],\n [20, 13, 3, 20, 4],\n [18, 19, 20, 3, 24],\n [4, 9, 4, 2, 19],\n [2, 7, 0, 5, 4],\n [19, 14, 17, 18, 14],\n [0, 3, 14, 17, 4],\n [22, 14, 10, 4, 13],\n [0, 12, 1, 4, 17],\n [9, 14, 20, 18, 19],\n [8, 13, 5, 4, 17],\n [1, 17, 0, 8, 3],\n [10, 13, 14, 2, 10],\n [13, 0, 8, 21, 4],\n [0, 15, 15, 11, 24],\n [18, 15, 14, 10, 4],\n [20, 18, 20, 0, 11],\n [17, 8, 21, 0, 11],\n [2, 7, 14, 17, 3],\n [19, 0, 15, 4, 17],\n [18, 11, 0, 19, 4],\n [19, 7, 8, 17, 3],\n [11, 20, 13, 0, 17],\n [4, 23, 2, 4, 11],\n [0, 14, 17, 19, 0],\n [15, 14, 8, 18, 4],\n [4, 23, 19, 17, 0],\n [9, 20, 3, 6, 4],\n [2, 14, 13, 3, 14],\n [8, 12, 15, 4, 11],\n [7, 0, 21, 14, 2],\n [12, 14, 11, 0, 17],\n [12, 0, 13, 11, 24]]"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_list = []\n",
    "for i in df[\"Word\"].values:\n",
    "    words_list.append(([dic[j] for j in i]))\n",
    "# words_list = torch.Tensor(words_list)\n",
    "words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-02-18T10:36:25.195623Z",
     "iopub.status.busy": "2023-02-18T10:36:25.195426Z",
     "iopub.status.idle": "2023-02-18T10:36:25.218153Z",
     "shell.execute_reply": "2023-02-18T10:36:25.217742Z",
     "shell.execute_reply.started": "2023-02-18T10:36:25.195608Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[[0.01, 0.03, 0.23, 0.39, 0.24, 0.09, 0.01],\n [0.01, 0.05, 0.23, 0.31, 0.24, 0.14, 0.02],\n [0.01, 0.03, 0.13, 0.27, 0.3, 0.22, 0.04],\n [0.01, 0.04, 0.16, 0.3, 0.3, 0.17, 0.02],\n [0.01, 0.09, 0.35, 0.34, 0.16, 0.05, 0.01],\n [0.01, 0.02, 0.13, 0.29, 0.31, 0.2, 0.03],\n [0.01, 0.04, 0.21, 0.3, 0.24, 0.15, 0.05],\n [0.01, 0.09, 0.35, 0.34, 0.16, 0.05, 0.01],\n [0.01, 0.09, 0.32, 0.32, 0.18, 0.07, 0.01],\n [0.01, 0.08, 0.32, 0.32, 0.18, 0.08, 0.02],\n [0.01, 0.02, 0.11, 0.24, 0.31, 0.26, 0.06],\n [0.01, 0.16, 0.37, 0.28, 0.12, 0.04, 0.01],\n [0.01, 0.08, 0.29, 0.34, 0.2, 0.08, 0.01],\n [0.01, 0.08, 0.3, 0.33, 0.19, 0.07, 0.01],\n [0.01, 0.03, 0.17, 0.33, 0.29, 0.15, 0.03],\n [0.01, 0.05, 0.28, 0.38, 0.2, 0.07, 0.01],\n [0.01, 0.01, 0.11, 0.29, 0.33, 0.21, 0.04],\n [0.01, 0.06, 0.25, 0.34, 0.23, 0.09, 0.01],\n [0.01, 0.04, 0.22, 0.37, 0.24, 0.1, 0.02],\n [0.01, 0.09, 0.29, 0.33, 0.19, 0.07, 0.01],\n [0.01, 0.04, 0.17, 0.3, 0.27, 0.17, 0.04],\n [0.01, 0.07, 0.29, 0.35, 0.2, 0.08, 0.01],\n [0.0, 0.02, 0.18, 0.39, 0.27, 0.12, 0.02],\n [0.01, 0.1, 0.25, 0.27, 0.19, 0.12, 0.05],\n [0.01, 0.13, 0.34, 0.3, 0.15, 0.06, 0.01],\n [0.03, 0.13, 0.32, 0.29, 0.16, 0.07, 0.01],\n [0.01, 0.07, 0.22, 0.28, 0.25, 0.14, 0.04],\n [0.01, 0.1, 0.28, 0.31, 0.19, 0.09, 0.02],\n [0.01, 0.04, 0.22, 0.36, 0.25, 0.11, 0.02],\n [0.01, 0.03, 0.17, 0.33, 0.27, 0.16, 0.03],\n [0.01, 0.03, 0.13, 0.24, 0.3, 0.24, 0.05],\n [0.01, 0.1, 0.2, 0.24, 0.24, 0.17, 0.03],\n [0.01, 0.05, 0.22, 0.34, 0.25, 0.11, 0.02],\n [0.01, 0.08, 0.26, 0.32, 0.21, 0.1, 0.02],\n [0.01, 0.04, 0.18, 0.3, 0.28, 0.16, 0.03],\n [0.01, 0.07, 0.23, 0.34, 0.24, 0.1, 0.01],\n [0.01, 0.06, 0.29, 0.34, 0.21, 0.08, 0.01],\n [0.01, 0.06, 0.25, 0.33, 0.22, 0.11, 0.02],\n [0.01, 0.06, 0.25, 0.33, 0.22, 0.11, 0.02],\n [0.01, 0.04, 0.2, 0.31, 0.26, 0.15, 0.03],\n [0.01, 0.06, 0.16, 0.23, 0.24, 0.21, 0.09],\n [0.01, 0.03, 0.15, 0.29, 0.27, 0.19, 0.07],\n [0.01, 0.01, 0.08, 0.19, 0.31, 0.3, 0.1],\n [0.01, 0.04, 0.21, 0.32, 0.26, 0.14, 0.03],\n [0.01, 0.09, 0.26, 0.3, 0.21, 0.1, 0.02],\n [0.01, 0.14, 0.38, 0.3, 0.12, 0.04, 0.0],\n [0.01, 0.05, 0.16, 0.24, 0.25, 0.22, 0.08],\n [0.01, 0.06, 0.21, 0.32, 0.25, 0.12, 0.02],\n [0.01, 0.02, 0.1, 0.29, 0.33, 0.21, 0.04],\n [0.01, 0.05, 0.26, 0.34, 0.22, 0.1, 0.02],\n [0.01, 0.09, 0.33, 0.33, 0.16, 0.07, 0.01],\n [0.01, 0.08, 0.3, 0.36, 0.18, 0.06, 0.01],\n [0.01, 0.02, 0.17, 0.35, 0.3, 0.13, 0.02],\n [0.01, 0.07, 0.26, 0.31, 0.21, 0.11, 0.02],\n [0.01, 0.08, 0.29, 0.34, 0.19, 0.08, 0.01],\n [0.01, 0.05, 0.2, 0.35, 0.26, 0.12, 0.02],\n [0.01, 0.09, 0.25, 0.29, 0.22, 0.12, 0.03],\n [0.01, 0.08, 0.33, 0.34, 0.17, 0.07, 0.01],\n [0.01, 0.09, 0.3, 0.34, 0.19, 0.07, 0.01],\n [0.01, 0.05, 0.18, 0.31, 0.28, 0.15, 0.02],\n [0.01, 0.05, 0.26, 0.37, 0.22, 0.08, 0.01],\n [0.0, 0.08, 0.31, 0.34, 0.19, 0.07, 0.01],\n [0.01, 0.06, 0.14, 0.18, 0.17, 0.24, 0.2],\n [0.01, 0.07, 0.29, 0.35, 0.2, 0.07, 0.01],\n [0.01, 0.04, 0.23, 0.36, 0.24, 0.1, 0.01],\n [0.0, 0.05, 0.19, 0.33, 0.28, 0.13, 0.02],\n [0.01, 0.16, 0.32, 0.3, 0.16, 0.06, 0.01],\n [0.01, 0.07, 0.19, 0.22, 0.19, 0.18, 0.15],\n [0.01, 0.05, 0.18, 0.3, 0.26, 0.16, 0.03],\n [0.01, 0.08, 0.31, 0.34, 0.19, 0.06, 0.01],\n [0.0, 0.05, 0.21, 0.32, 0.26, 0.14, 0.03],\n [0.0, 0.04, 0.2, 0.33, 0.27, 0.13, 0.02],\n [0.02, 0.14, 0.36, 0.3, 0.13, 0.04, 0.0],\n [0.0, 0.02, 0.19, 0.36, 0.27, 0.13, 0.02],\n [0.01, 0.04, 0.22, 0.35, 0.26, 0.11, 0.02],\n [0.01, 0.14, 0.35, 0.31, 0.14, 0.05, 0.01],\n [0.0, 0.05, 0.29, 0.36, 0.2, 0.07, 0.01],\n [0.0, 0.02, 0.13, 0.31, 0.33, 0.18, 0.03],\n [0.01, 0.02, 0.18, 0.44, 0.26, 0.26, 0.09],\n [0.01, 0.06, 0.17, 0.22, 0.2, 0.21, 0.14],\n [0.0, 0.03, 0.17, 0.3, 0.28, 0.17, 0.04],\n [0.0, 0.05, 0.16, 0.24, 0.27, 0.21, 0.06],\n [0.0, 0.02, 0.09, 0.26, 0.32, 0.24, 0.08],\n [0.01, 0.04, 0.19, 0.27, 0.26, 0.18, 0.05],\n [0.01, 0.16, 0.33, 0.28, 0.15, 0.06, 0.01],\n [0.0, 0.02, 0.1, 0.24, 0.32, 0.26, 0.06],\n [0.0, 0.03, 0.16, 0.31, 0.3, 0.16, 0.03],\n [0.0, 0.02, 0.14, 0.32, 0.32, 0.17, 0.03],\n [0.0, 0.02, 0.13, 0.33, 0.33, 0.17, 0.03],\n [0.0, 0.02, 0.14, 0.31, 0.31, 0.19, 0.04],\n [0.01, 0.12, 0.23, 0.26, 0.21, 0.13, 0.04],\n [0.02, 0.21, 0.36, 0.26, 0.11, 0.04, 0.01],\n [0.01, 0.1, 0.31, 0.34, 0.18, 0.06, 0.01],\n [0.0, 0.03, 0.2, 0.33, 0.27, 0.14, 0.02],\n [0.01, 0.05, 0.24, 0.36, 0.23, 0.09, 0.01],\n [0.01, 0.04, 0.29, 0.42, 0.18, 0.05, 0.01],\n [0.0, 0.06, 0.24, 0.35, 0.24, 0.1, 0.01],\n [0.01, 0.11, 0.22, 0.25, 0.21, 0.15, 0.05],\n [0.0, 0.03, 0.19, 0.4, 0.28, 0.09, 0.01],\n [0.0, 0.04, 0.2, 0.35, 0.27, 0.11, 0.02],\n [0.01, 0.08, 0.3, 0.36, 0.18, 0.06, 0.01],\n [0.0, 0.02, 0.1, 0.19, 0.19, 0.23, 0.26],\n [0.0, 0.05, 0.2, 0.34, 0.27, 0.12, 0.02],\n [0.0, 0.02, 0.11, 0.3, 0.33, 0.21, 0.04],\n [0.02, 0.19, 0.39, 0.28, 0.1, 0.03, 0.0],\n [0.01, 0.06, 0.25, 0.34, 0.23, 0.1, 0.01],\n [0.0, 0.07, 0.27, 0.34, 0.22, 0.09, 0.01],\n [0.0, 0.03, 0.13, 0.29, 0.32, 0.19, 0.04],\n [0.01, 0.13, 0.32, 0.31, 0.16, 0.06, 0.01],\n [0.0, 0.06, 0.26, 0.36, 0.22, 0.08, 0.01],\n [0.0, 0.02, 0.12, 0.27, 0.3, 0.22, 0.07],\n [0.0, 0.02, 0.1, 0.25, 0.35, 0.23, 0.04],\n [0.0, 0.01, 0.09, 0.26, 0.37, 0.23, 0.03],\n [0.01, 0.1, 0.23, 0.29, 0.24, 0.11, 0.02],\n [0.01, 0.08, 0.24, 0.33, 0.23, 0.1, 0.01],\n [0.06, 0.26, 0.32, 0.22, 0.1, 0.03, 0.0],\n [0.0, 0.03, 0.16, 0.26, 0.24, 0.19, 0.12],\n [0.0, 0.04, 0.2, 0.35, 0.26, 0.12, 0.02],\n [0.0, 0.03, 0.25, 0.39, 0.24, 0.09, 0.01],\n [0.0, 0.02, 0.1, 0.3, 0.34, 0.2, 0.04],\n [0.01, 0.14, 0.32, 0.3, 0.17, 0.06, 0.01],\n [0.0, 0.02, 0.16, 0.38, 0.29, 0.12, 0.02],\n [0.0, 0.09, 0.26, 0.32, 0.21, 0.09, 0.01],\n [0.0, 0.02, 0.16, 0.37, 0.31, 0.13, 0.02],\n [0.0, 0.06, 0.33, 0.38, 0.17, 0.05, 0.01],\n [0.01, 0.1, 0.31, 0.34, 0.18, 0.07, 0.01],\n [0.0, 0.04, 0.16, 0.29, 0.29, 0.18, 0.04],\n [0.0, 0.02, 0.14, 0.32, 0.33, 0.16, 0.02],\n [0.0, 0.04, 0.22, 0.37, 0.26, 0.1, 0.01],\n [0.0, 0.08, 0.34, 0.35, 0.17, 0.05, 0.01],\n [0.0, 0.04, 0.19, 0.33, 0.27, 0.14, 0.03],\n [0.01, 0.04, 0.17, 0.28, 0.26, 0.18, 0.06],\n [0.01, 0.09, 0.28, 0.34, 0.2, 0.08, 0.01],\n [0.01, 0.07, 0.26, 0.36, 0.21, 0.08, 0.01],\n [0.0, 0.05, 0.25, 0.37, 0.22, 0.09, 0.02],\n [0.0, 0.05, 0.26, 0.35, 0.24, 0.09, 0.01],\n [0.0, 0.02, 0.09, 0.25, 0.33, 0.24, 0.06],\n [0.0, 0.07, 0.28, 0.34, 0.21, 0.08, 0.01],\n [0.0, 0.08, 0.36, 0.33, 0.17, 0.06, 0.01],\n [0.0, 0.04, 0.27, 0.38, 0.22, 0.07, 0.01],\n [0.0, 0.06, 0.17, 0.33, 0.29, 0.13, 0.02],\n [0.0, 0.06, 0.28, 0.36, 0.21, 0.08, 0.01],\n [0.0, 0.06, 0.27, 0.34, 0.21, 0.1, 0.02],\n [0.0, 0.05, 0.21, 0.32, 0.25, 0.14, 0.03],\n [0.0, 0.02, 0.16, 0.37, 0.3, 0.13, 0.02],\n [0.01, 0.13, 0.38, 0.32, 0.13, 0.03, 0.0],\n [0.0, 0.05, 0.22, 0.35, 0.25, 0.11, 0.01],\n [0.0, 0.06, 0.28, 0.39, 0.2, 0.06, 0.01],\n [0.0, 0.02, 0.14, 0.35, 0.35, 0.13, 0.01],\n [0.0, 0.03, 0.2, 0.4, 0.28, 0.08, 0.01],\n [0.0, 0.06, 0.22, 0.35, 0.24, 0.11, 0.02],\n [0.0, 0.06, 0.23, 0.33, 0.23, 0.12, 0.03],\n [0.0, 0.04, 0.25, 0.41, 0.22, 0.07, 0.01],\n [0.0, 0.02, 0.12, 0.28, 0.32, 0.21, 0.05],\n [0.01, 0.12, 0.3, 0.32, 0.18, 0.06, 0.01],\n [0.0, 0.03, 0.27, 0.38, 0.23, 0.07, 0.01],\n [0.02, 0.16, 0.34, 0.29, 0.14, 0.04, 0.01],\n [0.0, 0.03, 0.22, 0.38, 0.25, 0.1, 0.02],\n [0.0, 0.07, 0.3, 0.38, 0.19, 0.05, 0.01],\n [0.0, 0.06, 0.23, 0.35, 0.26, 0.1, 0.01],\n [0.0, 0.01, 0.09, 0.27, 0.36, 0.23, 0.04],\n [0.01, 0.1, 0.28, 0.32, 0.19, 0.08, 0.02],\n [0.0, 0.05, 0.3, 0.38, 0.21, 0.06, 0.01],\n [0.0, 0.08, 0.21, 0.31, 0.26, 0.12, 0.02],\n [0.0, 0.05, 0.21, 0.33, 0.27, 0.12, 0.02],\n [0.0, 0.04, 0.22, 0.41, 0.24, 0.07, 0.01],\n [0.0, 0.06, 0.23, 0.35, 0.24, 0.11, 0.02],\n [0.0, 0.03, 0.19, 0.39, 0.29, 0.1, 0.01],\n [0.0, 0.09, 0.37, 0.34, 0.13, 0.05, 0.01],\n [0.0, 0.06, 0.24, 0.35, 0.24, 0.09, 0.01],\n [0.0, 0.02, 0.16, 0.31, 0.31, 0.17, 0.03],\n [0.0, 0.01, 0.05, 0.22, 0.33, 0.28, 0.1],\n [0.0, 0.01, 0.12, 0.28, 0.28, 0.21, 0.09],\n [0.0, 0.05, 0.25, 0.41, 0.22, 0.06, 0.01],\n [0.0, 0.03, 0.14, 0.33, 0.33, 0.15, 0.02],\n [0.0, 0.02, 0.17, 0.38, 0.29, 0.12, 0.01],\n [0.0, 0.02, 0.13, 0.27, 0.29, 0.21, 0.07],\n [0.01, 0.06, 0.25, 0.36, 0.23, 0.09, 0.01],\n [0.0, 0.0, 0.04, 0.25, 0.44, 0.23, 0.04],\n [0.0, 0.02, 0.18, 0.36, 0.27, 0.15, 0.03],\n [0.01, 0.05, 0.24, 0.35, 0.25, 0.09, 0.01],\n [0.01, 0.06, 0.2, 0.27, 0.28, 0.16, 0.03],\n [0.0, 0.07, 0.24, 0.35, 0.24, 0.09, 0.01],\n [0.0, 0.03, 0.13, 0.35, 0.34, 0.14, 0.02],\n [0.01, 0.08, 0.27, 0.27, 0.17, 0.13, 0.07],\n [0.0, 0.07, 0.31, 0.38, 0.18, 0.04, 0.0],\n [0.0, 0.04, 0.16, 0.26, 0.25, 0.2, 0.08],\n [0.0, 0.02, 0.11, 0.32, 0.37, 0.17, 0.02],\n [0.0, 0.02, 0.17, 0.41, 0.28, 0.1, 0.02],\n [0.0, 0.03, 0.18, 0.39, 0.27, 0.1, 0.02],\n [0.0, 0.04, 0.22, 0.37, 0.27, 0.09, 0.01],\n [0.0, 0.05, 0.27, 0.38, 0.21, 0.07, 0.01],\n [0.0, 0.04, 0.14, 0.22, 0.22, 0.23, 0.15],\n [0.0, 0.06, 0.24, 0.36, 0.23, 0.09, 0.02],\n [0.0, 0.03, 0.26, 0.41, 0.23, 0.06, 0.01],\n [0.0, 0.02, 0.18, 0.39, 0.28, 0.1, 0.02],\n [0.02, 0.06, 0.19, 0.29, 0.24, 0.15, 0.04],\n [0.0, 0.04, 0.22, 0.32, 0.26, 0.13, 0.02],\n [0.0, 0.02, 0.15, 0.24, 0.22, 0.25, 0.13],\n [0.0, 0.01, 0.11, 0.36, 0.36, 0.14, 0.01],\n [0.0, 0.07, 0.26, 0.32, 0.21, 0.11, 0.02],\n [0.0, 0.05, 0.3, 0.38, 0.2, 0.06, 0.01],\n [0.0, 0.02, 0.14, 0.42, 0.31, 0.1, 0.01],\n [0.01, 0.08, 0.26, 0.33, 0.19, 0.1, 0.02],\n [0.0, 0.05, 0.2, 0.33, 0.27, 0.13, 0.02],\n [0.0, 0.0, 0.04, 0.17, 0.28, 0.35, 0.15],\n [0.01, 0.05, 0.17, 0.31, 0.29, 0.15, 0.03],\n [0.0, 0.04, 0.22, 0.39, 0.25, 0.08, 0.01],\n [0.0, 0.01, 0.09, 0.29, 0.34, 0.22, 0.05],\n [0.03, 0.17, 0.31, 0.29, 0.15, 0.04, 0.0],\n [0.0, 0.02, 0.16, 0.39, 0.29, 0.12, 0.02],\n [0.0, 0.03, 0.24, 0.38, 0.25, 0.09, 0.01],\n [0.0, 0.02, 0.16, 0.39, 0.29, 0.12, 0.01],\n [0.0, 0.04, 0.2, 0.34, 0.27, 0.13, 0.02],\n [0.0, 0.06, 0.23, 0.37, 0.24, 0.08, 0.01],\n [0.0, 0.04, 0.18, 0.32, 0.29, 0.15, 0.02],\n [0.0, 0.01, 0.11, 0.33, 0.25, 0.22, 0.07],\n [0.0, 0.02, 0.17, 0.33, 0.28, 0.16, 0.04],\n [0.0, 0.04, 0.17, 0.3, 0.27, 0.17, 0.05],\n [0.0, 0.03, 0.19, 0.39, 0.29, 0.09, 0.01],\n [0.01, 0.06, 0.28, 0.38, 0.21, 0.06, 0.01],\n [0.0, 0.03, 0.22, 0.43, 0.25, 0.07, 0.01],\n [0.0, 0.04, 0.23, 0.36, 0.26, 0.1, 0.01],\n [0.01, 0.22, 0.32, 0.26, 0.14, 0.05, 0.01],\n [0.01, 0.07, 0.19, 0.27, 0.24, 0.17, 0.05],\n [0.0, 0.07, 0.33, 0.37, 0.17, 0.05, 0.0],\n [0.0, 0.02, 0.13, 0.32, 0.32, 0.17, 0.03],\n [0.0, 0.02, 0.21, 0.41, 0.26, 0.09, 0.01],\n [0.01, 0.08, 0.29, 0.36, 0.2, 0.06, 0.01],\n [0.0, 0.06, 0.29, 0.34, 0.21, 0.08, 0.01],\n [0.0, 0.02, 0.16, 0.33, 0.29, 0.16, 0.04],\n [0.0, 0.02, 0.11, 0.24, 0.31, 0.25, 0.08],\n [0.01, 0.06, 0.32, 0.38, 0.18, 0.05, 0.0],\n [0.0, 0.04, 0.29, 0.4, 0.21, 0.06, 0.01],\n [0.0, 0.05, 0.12, 0.2, 0.32, 0.26, 0.05],\n [0.0, 0.02, 0.18, 0.41, 0.28, 0.09, 0.01],\n [0.01, 0.12, 0.32, 0.34, 0.16, 0.05, 0.01],\n [0.0, 0.01, 0.09, 0.27, 0.31, 0.25, 0.07],\n [0.0, 0.06, 0.25, 0.36, 0.23, 0.08, 0.01],\n [0.0, 0.01, 0.16, 0.47, 0.29, 0.07, 0.01],\n [0.0, 0.04, 0.19, 0.27, 0.21, 0.16, 0.13],\n [0.0, 0.03, 0.17, 0.37, 0.28, 0.12, 0.02],\n [0.0, 0.04, 0.21, 0.32, 0.22, 0.13, 0.07],\n [0.0, 0.08, 0.29, 0.4, 0.18, 0.04, 0.0],\n [0.0, 0.04, 0.19, 0.34, 0.27, 0.13, 0.03],\n [0.0, 0.01, 0.14, 0.4, 0.3, 0.12, 0.02],\n [0.0, 0.01, 0.07, 0.27, 0.38, 0.23, 0.04],\n [0.0, 0.03, 0.19, 0.4, 0.28, 0.09, 0.01],\n [0.01, 0.05, 0.24, 0.41, 0.23, 0.05, 0.0],\n [0.01, 0.12, 0.32, 0.34, 0.16, 0.04, 0.0],\n [0.0, 0.0, 0.04, 0.11, 0.15, 0.22, 0.48],\n [0.0, 0.11, 0.37, 0.36, 0.12, 0.03, 0.0],\n [0.01, 0.09, 0.36, 0.35, 0.14, 0.04, 0.0],\n [0.0, 0.05, 0.24, 0.25, 0.18, 0.17, 0.11],\n [0.0, 0.06, 0.2, 0.33, 0.27, 0.12, 0.02],\n [0.0, 0.05, 0.3, 0.35, 0.21, 0.08, 0.01],\n [0.01, 0.14, 0.35, 0.29, 0.15, 0.05, 0.01],\n [0.0, 0.06, 0.3, 0.39, 0.19, 0.05, 0.0],\n [0.01, 0.14, 0.29, 0.28, 0.16, 0.08, 0.03],\n [0.0, 0.1, 0.25, 0.34, 0.22, 0.08, 0.01],\n [0.0, 0.05, 0.23, 0.38, 0.24, 0.07, 0.01],\n [0.0, 0.02, 0.18, 0.38, 0.28, 0.11, 0.02],\n [0.0, 0.03, 0.21, 0.38, 0.26, 0.09, 0.01],\n [0.0, 0.04, 0.23, 0.36, 0.24, 0.11, 0.02],\n [0.0, 0.08, 0.31, 0.35, 0.2, 0.06, 0.01],\n [0.0, 0.04, 0.16, 0.34, 0.31, 0.12, 0.01],\n [0.0, 0.06, 0.28, 0.4, 0.2, 0.05, 0.01],\n [0.01, 0.1, 0.3, 0.33, 0.18, 0.08, 0.02],\n [0.0, 0.03, 0.17, 0.35, 0.28, 0.13, 0.03],\n [0.0, 0.09, 0.3, 0.35, 0.19, 0.06, 0.01],\n [0.01, 0.1, 0.38, 0.34, 0.13, 0.03, 0.0],\n [0.0, 0.02, 0.11, 0.23, 0.29, 0.24, 0.11],\n [0.0, 0.02, 0.15, 0.35, 0.31, 0.14, 0.02],\n [0.0, 0.02, 0.13, 0.32, 0.32, 0.17, 0.04],\n [0.0, 0.03, 0.12, 0.29, 0.33, 0.2, 0.03],\n [0.0, 0.04, 0.28, 0.38, 0.21, 0.08, 0.01],\n [0.0, 0.02, 0.13, 0.25, 0.28, 0.21, 0.11],\n [0.0, 0.05, 0.23, 0.35, 0.25, 0.11, 0.02],\n [0.0, 0.03, 0.23, 0.44, 0.24, 0.06, 0.0],\n [0.0, 0.07, 0.18, 0.2, 0.15, 0.16, 0.23],\n [0.01, 0.08, 0.29, 0.36, 0.19, 0.06, 0.01],\n [0.01, 0.12, 0.34, 0.32, 0.16, 0.05, 0.01],\n [0.0, 0.05, 0.24, 0.38, 0.23, 0.08, 0.01],\n [0.0, 0.03, 0.23, 0.39, 0.24, 0.09, 0.02],\n [0.0, 0.05, 0.29, 0.4, 0.2, 0.05, 0.0],\n [0.0, 0.04, 0.18, 0.3, 0.28, 0.17, 0.03],\n [0.0, 0.07, 0.32, 0.36, 0.19, 0.06, 0.01],\n [0.0, 0.01, 0.04, 0.14, 0.27, 0.37, 0.18],\n [0.0, 0.07, 0.27, 0.35, 0.22, 0.08, 0.01],\n [0.0, 0.02, 0.13, 0.35, 0.32, 0.15, 0.03],\n [0.0, 0.06, 0.28, 0.37, 0.21, 0.07, 0.01],\n [0.0, 0.04, 0.22, 0.35, 0.24, 0.12, 0.03],\n [0.0, 0.07, 0.28, 0.36, 0.21, 0.07, 0.01],\n [0.0, 0.03, 0.15, 0.32, 0.32, 0.16, 0.02],\n [0.0, 0.02, 0.11, 0.29, 0.35, 0.19, 0.03],\n [0.0, 0.03, 0.26, 0.41, 0.23, 0.07, 0.01],\n [0.0, 0.01, 0.14, 0.37, 0.33, 0.14, 0.02],\n [0.0, 0.06, 0.3, 0.39, 0.2, 0.06, 0.01],\n [0.01, 0.18, 0.31, 0.3, 0.15, 0.04, 0.01],\n [0.0, 0.05, 0.34, 0.43, 0.15, 0.03, 0.0],\n [0.05, 0.14, 0.31, 0.29, 0.15, 0.04, 0.01],\n [0.02, 0.19, 0.3, 0.27, 0.15, 0.06, 0.02],\n [0.0, 0.06, 0.26, 0.36, 0.23, 0.07, 0.01],\n [0.0, 0.04, 0.24, 0.37, 0.24, 0.09, 0.01],\n [0.01, 0.16, 0.38, 0.31, 0.11, 0.03, 0.01],\n [0.01, 0.11, 0.31, 0.33, 0.18, 0.05, 0.01],\n [0.0, 0.05, 0.25, 0.38, 0.23, 0.08, 0.01],\n [0.0, 0.04, 0.22, 0.38, 0.25, 0.09, 0.01],\n [0.0, 0.08, 0.25, 0.3, 0.21, 0.13, 0.03],\n [0.01, 0.06, 0.26, 0.36, 0.21, 0.08, 0.01],\n [0.0, 0.05, 0.21, 0.31, 0.24, 0.15, 0.04],\n [0.0, 0.05, 0.16, 0.23, 0.24, 0.22, 0.1],\n [0.0, 0.14, 0.35, 0.33, 0.14, 0.04, 0.0],\n [0.0, 0.02, 0.23, 0.49, 0.2, 0.05, 0.01],\n [0.0, 0.07, 0.26, 0.35, 0.22, 0.09, 0.01],\n [0.01, 0.06, 0.17, 0.27, 0.27, 0.18, 0.05],\n [0.0, 0.05, 0.19, 0.33, 0.27, 0.13, 0.03],\n [0.01, 0.1, 0.26, 0.32, 0.21, 0.09, 0.01],\n [0.01, 0.12, 0.32, 0.3, 0.18, 0.06, 0.01],\n [0.05, 0.13, 0.25, 0.27, 0.19, 0.1, 0.02],\n [0.0, 0.08, 0.28, 0.4, 0.18, 0.05, 0.01],\n [0.0, 0.06, 0.28, 0.39, 0.19, 0.06, 0.01],\n [0.0, 0.1, 0.38, 0.35, 0.13, 0.03, 0.0],\n [0.0, 0.03, 0.19, 0.35, 0.29, 0.13, 0.02],\n [0.0, 0.06, 0.3, 0.33, 0.19, 0.1, 0.02],\n [0.0, 0.02, 0.11, 0.35, 0.36, 0.14, 0.02],\n [0.0, 0.06, 0.3, 0.33, 0.19, 0.09, 0.02],\n [0.0, 0.04, 0.35, 0.36, 0.17, 0.06, 0.01],\n [0.02, 0.17, 0.32, 0.29, 0.15, 0.05, 0.01],\n [0.0, 0.02, 0.1, 0.25, 0.36, 0.23, 0.04],\n [0.0, 0.06, 0.22, 0.33, 0.24, 0.12, 0.03],\n [0.0, 0.06, 0.29, 0.34, 0.21, 0.08, 0.02],\n [0.0, 0.03, 0.19, 0.33, 0.26, 0.14, 0.03],\n [0.0, 0.1, 0.36, 0.35, 0.14, 0.03, 0.0],\n [0.0, 0.03, 0.18, 0.43, 0.27, 0.08, 0.01],\n [0.01, 0.07, 0.24, 0.32, 0.24, 0.11, 0.01],\n [0.0, 0.05, 0.28, 0.38, 0.22, 0.07, 0.01],\n [0.0, 0.06, 0.31, 0.38, 0.19, 0.05, 0.0],\n [0.0, 0.03, 0.2, 0.39, 0.27, 0.1, 0.01],\n [0.0, 0.07, 0.27, 0.35, 0.22, 0.08, 0.01],\n [0.0, 0.07, 0.39, 0.38, 0.13, 0.03, 0.0],\n [0.0, 0.08, 0.28, 0.3, 0.2, 0.11, 0.03],\n [0.06, 0.14, 0.33, 0.27, 0.13, 0.05, 0.01],\n [0.01, 0.1, 0.47, 0.32, 0.09, 0.02, 0.0],\n [0.0, 0.05, 0.32, 0.4, 0.17, 0.04, 0.0],\n [0.0, 0.01, 0.13, 0.34, 0.34, 0.15, 0.02],\n [0.0, 0.07, 0.26, 0.35, 0.2, 0.1, 0.03],\n [0.02, 0.11, 0.34, 0.32, 0.15, 0.06, 0.01],\n [0.01, 0.05, 0.2, 0.35, 0.28, 0.1, 0.01],\n [0.0, 0.02, 0.08, 0.16, 0.26, 0.33, 0.14],\n [0.0, 0.02, 0.17, 0.35, 0.29, 0.14, 0.03],\n [0.0, 0.03, 0.21, 0.4, 0.25, 0.09, 0.01],\n [0.0, 0.02, 0.16, 0.38, 0.3, 0.12, 0.02],\n [0.0, 0.04, 0.21, 0.38, 0.26, 0.09, 0.01],\n [0.0, 0.02, 0.17, 0.37, 0.29, 0.12, 0.02]]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per = df.iloc[:, 6: 13]\n",
    "per = [([j / 100 for j in i]) for i in per.values]\n",
    "per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-02-18T10:36:25.218839Z",
     "iopub.status.busy": "2023-02-18T10:36:25.218686Z",
     "iopub.status.idle": "2023-02-18T10:36:25.223017Z",
     "shell.execute_reply": "2023-02-18T10:36:25.222608Z",
     "shell.execute_reply.started": "2023-02-18T10:36:25.218824Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(319, 36, 319, 36)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(words_list, per, test_size=0.1, random_state=50)\n",
    "len(x_train), len(x_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-02-18T10:36:25.224661Z",
     "iopub.status.busy": "2023-02-18T10:36:25.224502Z",
     "iopub.status.idle": "2023-02-18T10:36:25.228403Z",
     "shell.execute_reply": "2023-02-18T10:36:25.228011Z",
     "shell.execute_reply.started": "2023-02-18T10:36:25.224646Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([36, 5])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = torch.LongTensor(x_train)\n",
    "x_test = torch.LongTensor(x_test)\n",
    "y_train = torch.Tensor(y_train)\n",
    "y_test = torch.Tensor(y_test)\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-02-18T10:36:25.229077Z",
     "iopub.status.busy": "2023-02-18T10:36:25.228930Z",
     "iopub.status.idle": "2023-02-18T10:36:25.299320Z",
     "shell.execute_reply": "2023-02-18T10:36:25.298891Z",
     "shell.execute_reply.started": "2023-02-18T10:36:25.229062Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-02-18T10:36:25.300018Z",
     "iopub.status.busy": "2023-02-18T10:36:25.299865Z",
     "iopub.status.idle": "2023-02-18T10:36:25.304202Z",
     "shell.execute_reply": "2023-02-18T10:36:25.303726Z",
     "shell.execute_reply.started": "2023-02-18T10:36:25.300003Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.embedding = nn.Embedding(26, 5),\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(5, 30),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(30, 7),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        # out = [[j / sum(i) for j in i] for i in out.tolist()]\n",
    "        s = torch.sum(out, axis=1)\n",
    "        s.unsqueeze_(0)\n",
    "        s = s.repeat_interleave(7, axis=1).view(-1, 7)\n",
    "        return torch.div(out, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-02-18T10:36:25.304881Z",
     "iopub.status.busy": "2023-02-18T10:36:25.304729Z",
     "iopub.status.idle": "2023-02-18T10:36:27.660866Z",
     "shell.execute_reply": "2023-02-18T10:36:27.660018Z",
     "shell.execute_reply.started": "2023-02-18T10:36:25.304867Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model = MLP().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-02-18T10:36:27.661977Z",
     "iopub.status.busy": "2023-02-18T10:36:27.661781Z",
     "iopub.status.idle": "2023-02-18T10:36:27.667579Z",
     "shell.execute_reply": "2023-02-18T10:36:27.667170Z",
     "shell.execute_reply.started": "2023-02-18T10:36:27.661960Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.4141, -0.8780,  0.3245,  0.1524, -1.3400],\n        [ 0.1524, -0.8780, -1.8069, -1.6953,  0.2413],\n        [-0.5813, -0.0361,  1.2400, -2.4450,  0.3922],\n        ...,\n        [ 0.7993, -0.6880,  0.4141,  0.4141,  0.2413],\n        [-1.6953, -1.3400, -0.6880, -0.1886, -2.4450],\n        [-1.6953,  0.5624,  0.1547,  0.5624,  0.3245]],\n       grad_fn=<ViewBackward0>)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = nn.Embedding(26, 1)\n",
    "x_train = embedding(x_train)\n",
    "x_train = x_train.view(-1, 5)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-02-18T10:36:27.668292Z",
     "iopub.status.busy": "2023-02-18T10:36:27.668135Z",
     "iopub.status.idle": "2023-02-18T10:36:27.671780Z",
     "shell.execute_reply": "2023-02-18T10:36:27.671383Z",
     "shell.execute_reply.started": "2023-02-18T10:36:27.668277Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([36, 5])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = embedding(x_test)\n",
    "x_test = x_test.view(-1, 5)\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-02-18T10:36:27.672530Z",
     "iopub.status.busy": "2023-02-18T10:36:27.672321Z",
     "iopub.status.idle": "2023-02-18T10:36:27.675229Z",
     "shell.execute_reply": "2023-02-18T10:36:27.674823Z",
     "shell.execute_reply.started": "2023-02-18T10:36:27.672515Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x_train = x_train.to(device)\n",
    "x_test = x_test.to(device)\n",
    "y_train = y_train.to(device)\n",
    "y_test = y_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-02-18T10:36:27.675938Z",
     "iopub.status.busy": "2023-02-18T10:36:27.675783Z",
     "iopub.status.idle": "2023-02-18T10:36:27.679970Z",
     "shell.execute_reply": "2023-02-18T10:36:27.679558Z",
     "shell.execute_reply.started": "2023-02-18T10:36:27.675923Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def train(num_epochs):\n",
    "    pred = \"\"\n",
    "    for epoch in range(num_epochs):\n",
    "        pred = model(x_train)\n",
    "        # print(pred.tolist())\n",
    "        # print(pp)\n",
    "        loss = criterion(pred, y_train)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        train_l_sum = loss.item()\n",
    "        if epoch == 1:\n",
    "\n",
    "            print(\n",
    "                'epoch %d, loss %.4f'\n",
    "                % (epoch + 1, train_l_sum))\n",
    "            break\n",
    "    # px.line(y=np.array(y_train.cpu().detach_())[:, 0]).show()\n",
    "\n",
    "def test():\n",
    "    with torch.no_grad():\n",
    "        pred = model(x_test)\n",
    "        loss = criterion(pred, y_test)\n",
    "        print(loss)\n",
    "        print(pred[0])\n",
    "        print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-02-18T10:36:27.680729Z",
     "iopub.status.busy": "2023-02-18T10:36:27.680523Z",
     "iopub.status.idle": "2023-02-18T10:58:28.046559Z",
     "shell.execute_reply": "2023-02-18T10:58:28.045943Z",
     "shell.execute_reply.started": "2023-02-18T10:36:27.680714Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, loss 0.0154\n"
     ]
    }
   ],
   "source": [
    "train(500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-02-18T10:58:28.047656Z",
     "iopub.status.busy": "2023-02-18T10:58:28.047420Z",
     "iopub.status.idle": "2023-02-18T10:58:28.054168Z",
     "shell.execute_reply": "2023-02-18T10:58:28.053735Z",
     "shell.execute_reply.started": "2023-02-18T10:58:28.047638Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0157, device='cuda:0')\n",
      "tensor([0.1236, 0.1782, 0.1238, 0.1396, 0.1315, 0.1862, 0.1170],\n",
      "       device='cuda:0')\n",
      "tensor([0.0000, 0.0200, 0.1300, 0.3200, 0.3200, 0.1700, 0.0300],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-02-18T10:58:28.054933Z",
     "iopub.status.busy": "2023-02-18T10:58:28.054737Z",
     "iopub.status.idle": "2023-02-18T10:58:28.058589Z",
     "shell.execute_reply": "2023-02-18T10:58:28.058185Z",
     "shell.execute_reply.started": "2023-02-18T10:58:28.054917Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[[4, 4, 17, 8, 4]]"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = \"eerie\"\n",
    "w = [dic[i] for i in w]\n",
    "[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-02-18T10:58:28.059336Z",
     "iopub.status.busy": "2023-02-18T10:58:28.059146Z",
     "iopub.status.idle": "2023-02-18T10:58:28.063640Z",
     "shell.execute_reply": "2023-02-18T10:58:28.063234Z",
     "shell.execute_reply.started": "2023-02-18T10:58:28.059321Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.5624,  0.5624,  0.3245, -0.8780,  0.5624]], device='cuda:0',\n       grad_fn=<ToCopyBackward0>)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = embedding(torch.LongTensor([[4, 4, 17, 8, 4]])).view(-1, 5)\n",
    "w = w.to(device)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-02-18T10:58:28.064380Z",
     "iopub.status.busy": "2023-02-18T10:58:28.064187Z",
     "iopub.status.idle": "2023-02-18T10:58:28.068106Z",
     "shell.execute_reply": "2023-02-18T10:58:28.067712Z",
     "shell.execute_reply.started": "2023-02-18T10:58:28.064364Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.1341, 0.1455, 0.1652, 0.1399, 0.1440, 0.1485, 0.1227]],\n       device='cuda:0', grad_fn=<DivBackward0>)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
